{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# autoreload to cast any changes to the module files into the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import math\n",
    "import os, csv\n",
    "from datetime import date \n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "        \n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Note:\n",
    "'''\n",
    "Although it seems like we re-declare a new variable evertime we execute a shell, \n",
    "like in case of list_of_traj_dictionaries = [], \n",
    "Kaggle actually used the cached version of the variable. Does not happen on JupyterNotebook\n",
    "\n",
    "'''\n",
    "\n",
    "# references\n",
    "'''\n",
    "http://google.github.io/styleguide/pyguide.html\n",
    "https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html\n",
    "https://developers.google.com/edu/python/regular-expressions\n",
    "'''\n",
    "\n",
    "# configurations\n",
    "# this script is applicatble only for ring-molecules\n",
    "NUM_CARBON = 8\n",
    "NUM_ATOMS = NUM_CARBON + 2 + 5*2\n",
    "\n",
    "# C6-H9\n",
    "# C7-H10\n",
    "# C8-H11\n",
    "# C1-H12\n",
    "# C5-H13 & C5-H14\n",
    "# C4-H15 & C4-H16\n",
    "# C3-H17 & C3-H20\n",
    "# C2-H18 & C2-H19\n",
    "carbon_list = [6,7,8,1,5,5,4,4,3,3,2,2]\n",
    "hydrogen_list = [9,10,11,12,13,14,15,16,17,20,18,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new block \n",
    "# take in index, list \n",
    "# if(match | EOF) return a block \n",
    "def read_a_trajectory(index, line_list):\n",
    "    list_of_lines_per_block = [line_list[index][:-1]] # add line with trajectory \n",
    "    for line in line_list[index+1:]:\n",
    "        if (re.search(r'TRAJ\\d+', line)):\n",
    "            break\n",
    "        else:\n",
    "            list_of_lines_per_block.append(line[:-1])\n",
    "            \n",
    "    return list_of_lines_per_block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop file \n",
    "    # catch patterns\n",
    "    # read 20 lines into a block (list of lines/strings)\n",
    "    # append to list_of_blocks\n",
    "\n",
    "\n",
    "searchfile = open('./IC-angs-conflow.xyz', \"r\",encoding='utf-8')\n",
    "line_list = searchfile.readlines()\n",
    "line_list = [line for line in line_list if line != ' {} \\n'.format(NUM_ATOMS)]    # strip all lines with \" NUM_ATOMS \\n\"\n",
    "\n",
    "list_of_blocks_in_file = []\n",
    "\n",
    "for index, line in enumerate(line_list):\n",
    "    if re.search(r'TRAJ\\d+', line):\n",
    "        # create new block / trajectory\n",
    "        block_for_trajectory = read_a_trajectory(index,line_list)\n",
    "        \n",
    "        # append to list\n",
    "        list_of_blocks_in_file.append(block_for_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bondlength(coord_1,coord_2):\n",
    "    coordinates=[]\n",
    "    atom,x1,y1,z1 = coord_1.split()\n",
    "    atom2,x2,y2,z2 = coord_2.split()\n",
    "    \n",
    "    return math.sqrt(  (float(x2) - float(x1))**2 \n",
    "                     + (float(y2) - float(y1))**2 \n",
    "                     + (float(z2) - float(z1))**2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute block \n",
    "# Input: block\n",
    "# Output: dictionary_for_trajectory - in format \"TRAJ : 1, C1-C2: (double), C2-C3 (double), ... \"\n",
    "\n",
    "# functions to extractCooridnate() & compBondLength()   --  maybe put in e\n",
    "def compute(block):\n",
    "    dictionary_for_trajectory = {}\n",
    "    \n",
    "    dictionary_for_trajectory['TRAJ'] = re.findall('\\d+', block[0])[0]   # findall the numbers in the string block[0], return a list --> index [0] to get string value\n",
    "    \n",
    "    # C - C\n",
    "    for carbon in list(range(1, NUM_CARBON+1)): \n",
    "        if carbon == NUM_CARBON:\n",
    "            bond_title =\"C{}-C{}\".format(carbon,1)\n",
    "            dictionary_for_trajectory[bond_title] = compute_bondlength(block[carbon],block[1])\n",
    "        elif carbon != NUM_CARBON:     \n",
    "            bond_title =\"C{}-C{}\".format(carbon,carbon+1)\n",
    "            dictionary_for_trajectory[bond_title] = compute_bondlength(block[carbon],block[carbon + 1]) \n",
    "    # C - H\n",
    "    for carbon,hydro in zip(carbon_list,hydrogen_list):\n",
    "        bond_title =\"C{}-H{}\".format(carbon,hydro)\n",
    "        dictionary_for_trajectory[bond_title] = compute_bondlength(block[carbon],block[hydro])    \n",
    "\n",
    "    return dictionary_for_trajectory\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\output\\\\2020-06-04trajectory_bondlength.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5de540cd1342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mstorage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_computed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"trajectory_bondlength\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mfield_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_traj_dictionaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfield_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'excel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\output\\\\2020-06-04trajectory_bondlength.csv'"
     ]
    }
   ],
   "source": [
    "# loop through list of blocks \n",
    "list_of_traj_dictionaries = []\n",
    "\n",
    "for block in list_of_blocks_in_file:\n",
    "    \n",
    "    # compute(block)\n",
    "    dictionary_for_trajectory = compute(block)\n",
    "    \n",
    "    # create new entries in list_of_dictionaries \"Traj : 1, C1-C2: (double), C2-C3 (double), ... \"\n",
    "    list_of_traj_dictionaries.append(dictionary_for_trajectory)\n",
    "\n",
    "# write to csv\n",
    "date_computed = str(date.today())\n",
    "storage_path = os.path.join(\".\", \"output\", date_computed + \"_trajectory_bondlength\" + \".csv\")\n",
    "    \n",
    "with open(storage_path, 'w', newline='', encoding='utf-8') as csvFile:\n",
    "    field_names = list(list_of_traj_dictionaries[0].keys())\n",
    "    writer = csv.DictWriter(csvFile, fieldnames=field_names, dialect='excel')\n",
    "\n",
    "    writer.writeheader()\n",
    "    for trajectory in list_of_traj_dictionaries:\n",
    "        writer.writerow(trajectory)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loop file \n",
    "    # catch patterns\n",
    "    # read 20 lines into a block (list of lines/strings)\n",
    "    # append to list_of_blocks\n",
    "    \n",
    "\n",
    "# loop through list of blocks \n",
    "# for index in len(list_of_blocks)\n",
    "    # compute(block)\n",
    "        \n",
    "    # create new entries in list_of_dictionaries \"Traj : 1, C1-C2: (double), C2-C3 (double), ... \"\n",
    "        \n",
    "# write to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun with islice\n",
    "from itertools import islice\n",
    "number_of_lines = 22\n",
    "search_file = open('/kaggle/input/IC-angs-conflow.xyz', \"r\",encoding='utf-8')\n",
    "\n",
    "lines_cache = islice(search_file, number_of_lines)\n",
    "   \n",
    "for current_line in lines_cache:\n",
    "    print (current_line[:-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "# dictionary operations\n",
    "student = {}\n",
    "name = student[\"name\"] if \"name\" in student else \"Unknown\"\n",
    "name = student.get(\"name\", -1)\n",
    "print(name)\n",
    "\n",
    "\n",
    "\n",
    "# Iteration over the items\n",
    "for key, value in currencies.items():\n",
    "    print(f\"Key: {key}; Value: {value}\")\n",
    "\n",
    "# Key: America; Value: USD\n",
    "# Key: China; Value: CNY\n",
    "# Key: Britain; Value: GBP\n",
    "\n",
    "\n",
    "\n",
    "# Merging dictionaries\n",
    "# Merge dictionaries using update() - instead of create new and merge\n",
    "d0 = {\"a\": 0, \"b\": 1}\n",
    "d1 = {\"b\": 2, \"c\": 3}\n",
    "d0.update(d1)\n",
    "# d0\n",
    "# {'a': 0, 'b': 2, 'c': 3}\n",
    "\n",
    "\n",
    "# Merge dictionaries using unpacking **\n",
    "dict0 = {0: \"a\", 1: \"b\"}\n",
    "dict1 = {1: \"z\", 2: \"c\"}\n",
    "dict2 = {**dict0, **dict1}\n",
    "# dict2\n",
    "# {0: 'a', 1: 'z', 2: 'c'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
